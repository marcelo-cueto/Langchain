{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRUEBA DE REQUEST A WIKIPEDIA API\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL de la API de Wikipedia (para obtener datos en formato JSON)\n",
    "url = \"https://es.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Parámetros de la solicitud para obtener el resumen de una página\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"exintro\": True,\n",
    "    \"titles\": \"Albert Einstein\",\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Hacer la solicitud GET a la API de Wikipedia\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Comprobar si la respuesta fue exitosa\n",
    "if response.status_code == 200:\n",
    "    # Obtener los datos en formato JSON\n",
    "    data = response.json()\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    for page_id, page_data in pages.items():\n",
    "        print(f\"Título: {page_data['title']}\")\n",
    "        print(f\"Extracto: {page_data['extract']}\")\n",
    "else:\n",
    "    print(f\"Error al conectarse a Wikipedia: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\marce\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marce\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marce\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marce\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marce\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.7.0\n",
      "    Uninstalling requests-2.7.0:\n",
      "      Successfully uninstalled requests-2.7.0\n",
      "Successfully installed requests-2.32.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'collections' (c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# URL para la API de Instant Answers de DuckDuckGo\u001b[39;00m\n\u001b[0;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.duckduckgo.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:58\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request, Response, PreparedRequest\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m request, get, head, post, patch, put, delete, options\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\utils.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m certs\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_http_list \u001b[38;5;28;01mas\u001b[39;00m _parse_list_header\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (quote, urlparse, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m, OrderedDict, unquote, is_py2,\n\u001b[0;32m     28\u001b[0m                      builtin_str, getproxies, proxy_bypass, urlunparse,\n\u001b[0;32m     29\u001b[0m                      basestring)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcookies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsCookieJar, cookiejar_from_dict\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\compat.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mpythoncompat\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chardet\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Pythons\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Syntax sugar.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\packages\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urllib3\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\packages\\urllib3\\__init__.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m __license__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.10.4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectionpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     HTTPConnectionPool,\n\u001b[0;32m     12\u001b[0m     HTTPSConnectionPool,\n\u001b[0;32m     13\u001b[0m     connection_from_url\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilepost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m encode_multipart_formdata\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     port_by_scheme,\n\u001b[0;32m     33\u001b[0m     DummyConnection,\n\u001b[0;32m     34\u001b[0m     HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection,\n\u001b[0;32m     35\u001b[0m     HTTPException, BaseSSLError, \u001b[38;5;167;01mConnectionError\u001b[39;00m\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestMethods\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_connection_dropped\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Retry\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\packages\\urllib3\\response.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msocket\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timeout \u001b[38;5;28;01mas\u001b[39;00m SocketTimeout\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPHeaderDict\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     ProtocolError, DecodeError, ReadTimeoutError, ResponseNotChunked\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_types \u001b[38;5;28;01mas\u001b[39;00m basestring, binary_type, PY3\n",
      "File \u001b[1;32mc:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\packages\\urllib3\\_collections.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mapping, MutableMapping\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RLock\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Mapping' from 'collections' (c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL para la API de Instant Answers de DuckDuckGo\n",
    "url = \"https://api.duckduckgo.com/\"\n",
    "\n",
    "# Parámetros de la solicitud\n",
    "params = {\n",
    "    \"q\": \"¿Cuál es el significado de la vida?\",  # La pregunta que deseas hacer\n",
    "    \"format\": \"json\",  # Formato de respuesta\n",
    "    \"RelatedTopics\":True, \n",
    "    #\"no_html\": 1,  # Opcional, para evitar HTML en la respuesta\n",
    "    #\"skip_disambig\": 1  # Opcional, para evitar respuestas de desambiguación\n",
    "}\n",
    "\n",
    "# Enviar la solicitud GET\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Verificar la respuesta\n",
    "if response.status_code == 200:\n",
    "    print(\"Respuesta de DuckDuckGo:\", response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://openlibrary.org/search.json\"\n",
    "params = {\n",
    "    \"title\": \"The Meaning of Life\"  # Cambia al título o tema deseado\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "if response.status_code == 200:\n",
    "    books = response.json()[\"docs\"]\n",
    "    for book in books[:5]:  # Muestra los primeros 5 resultados\n",
    "        print(\"Título:\", book.get(\"title\"), \"| Autor:\", book.get(\"author_name\"))\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta de Ollama: {'model': 'llama3.1', 'created_at': '2024-11-09T13:22:04.608028488Z', 'response': '```json\\n{\\n  \"texto\": \"¡Descubre el poder de Kubernetes! Con esta tecnología de containerización, puedes gestionar y escalarte aplicaciones con facilidad. ¿Quieres saber más? Mírate la conferencia que te compartimos en la carpeta \\'Resursos\\' \",\\n  \"imagenes\": [\\n    {\\n      \"url\": \"https://picsum.photos/200\",\\n      \"descripcion\": \"Una imagen de un contenedor ejecutándose\"\\n    },\\n    {\\n      \"url\": \"https://picsum.photos/201\",\\n      \"descripcion\": \"Una imagen del diagrama de Kubernetes\"\\n    }\\n  ],\\n  \"hashtags\": [\\n    \"#Kubernetes\",\\n    \"#Containerización\",\\n    \"#DesarrolloDeSoftware\",\\n    \"#IngenieríaDelSoftware\"\\n  ]\\n}\\n```', 'done': True, 'done_reason': 'stop', 'context': [128006, 882, 128007, 271, 1079, 76149, 264, 1208, 56001, 80440, 665, 55956, 4823, 25, 1922, 373, 653, 1772, 409, 52104, 15482, 597, 30927, 128009, 128006, 78191, 128007, 271, 74694, 2285, 198, 517, 220, 330, 58103, 794, 330, 40932, 11312, 64359, 658, 29638, 409, 67474, 0, 1221, 15491, 41934, 54433, 409, 5593, 42600, 11, 60045, 59471, 277, 379, 27533, 20430, 30540, 12712, 390, 58424, 5969, 13, 29386, 2232, 65588, 42104, 11158, 30, 386, 2483, 7853, 1208, 49843, 8968, 1744, 1028, 39667, 25075, 665, 1208, 39739, 1955, 364, 1079, 49022, 6, 22549, 220, 330, 86385, 794, 2330, 262, 341, 415, 330, 1103, 794, 330, 2485, 1129, 74557, 372, 65448, 14, 1049, 761, 415, 330, 40338, 794, 330, 65194, 41669, 409, 653, 687, 77221, 50271, 332, 48680, 974, 702, 262, 1173, 262, 341, 415, 330, 1103, 794, 330, 2485, 1129, 74557, 372, 65448, 14, 679, 761, 415, 330, 40338, 794, 330, 65194, 41669, 1624, 13861, 64, 409, 67474, 702, 262, 457, 220, 3291, 220, 330, 31309, 794, 2330, 262, 5993, 42, 30927, 761, 262, 5993, 4603, 42600, 761, 262, 5993, 5001, 277, 44784, 1951, 19805, 761, 262, 5993, 644, 4469, 1291, 7583, 16939, 19805, 702, 220, 5243, 534, 74694], 'total_duration': 48259827497, 'load_duration': 3857084311, 'prompt_eval_count': 29, 'prompt_eval_duration': 4103000000, 'eval_count': 169, 'eval_duration': 40297000000}\n"
     ]
    }
   ],
   "source": [
    "#PRUEBA DE SOLICITUD API A OLLAMA MODEL EN DOCKER\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL correcta para interactuar con el API de Ollama\n",
    "url = \"http://middleearthar.ddns.net:11434/api/generate\"\n",
    "\n",
    "# Datos de la solicitud\n",
    "data = {\n",
    "    \"model\": \"llama3.1\",  # Cambia al modelo que deseas usar\n",
    "    \"prompt\": \"Responde a la siguiente pregunta en formato JSON: creame un post de instagram sobre kubernetes\",\n",
    "    #\"format\": \"json\",  # El formato de la respuesta\n",
    "    \"stream\": False  # Opcional, pero si no quieres respuestas por streaming\n",
    "}\n",
    "# Enviar la solicitud POST\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Verificar la respuesta\n",
    "if response.status_code == 200:\n",
    "    print(\"Respuesta de Ollama:\", response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\python312\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\python312\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in c:\\python312\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\python312\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#pip install llama-index\n",
    "#!pip install transformers pdfplumber\n",
    "!pip install ollama\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[0;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://middleearthar.ddns.net:11434\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "from ollama import Client\n",
    "\n",
    "\n",
    "client = Client(host='http://middleearthar.ddns.net:11434')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.wolframalpha.com/v1/result\"\n",
    "params = {\n",
    "    \"appid\": \"VLVTJ3-KW3TQPUGVG\",  # Necesitas una clave API gratuita de Wolfram Alpha\n",
    "    \"i\": \"Eres un experto en geografía y tienes un conocimiento detallado de ciudades y países. Responde de manera detallada y en formato JSON: ¿Dónde queda Buenos Aires?\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "if response.status_code == 200:\n",
    "    print(\"Respuesta de Wolfram Alpha:\", response.text)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LANGCHAIN OLLAMA MODEL:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROBANDO AGREGADO DE HERRAMIENTAS COMO WIKIPEDIA Y DUCKDUCKGO\n",
    "\n",
    "El código ahora también utiliza MariaDB como almacenamiento de memoria y LlamaIndex para una indexación rápida y búsqueda de consultas previas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import mariadb\n",
    "import json\n",
    "import webbrowser\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar stopwords de NLTK si no están instaladas\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Definición del modelo Ollama LLM (usando Ollama en Docker)\n",
    "class OllamaLLM:\n",
    "    def __init__(self, api_url=\"http://localhost:11434/api/generate\", model=\"llama3.2:1b\"):\n",
    "        self.api_url = api_url\n",
    "        self.model = model\n",
    "\n",
    "    def generate(self, prompt: str, stream: bool = False):\n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": stream\n",
    "        }\n",
    "        try:\n",
    "            logging.debug(f\"Enviando solicitud a Ollama con el modelo {self.model} y el prompt '{prompt}'\")\n",
    "            response = requests.post(self.api_url, json=data)\n",
    "            response.raise_for_status()  # Lanzar excepción si hay error HTTP\n",
    "            result = response.json().get('response', '')\n",
    "            logging.debug(f\"Respuesta de Ollama: {result}\")\n",
    "            \n",
    "            if result.strip():  # Asegurarse de que la respuesta no esté vacía\n",
    "                return result\n",
    "            else:\n",
    "                logging.error(\"Ollama devolvió una respuesta vacía.\")\n",
    "                return None\n",
    "        except requests.Timeout:\n",
    "            logging.error(\"Tiempo de espera agotado para Ollama.\")\n",
    "            return None\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"Error en Ollama: {e}\")\n",
    "            return None\n",
    "\n",
    "# Clase de memoria utilizando MariaDB\n",
    "class MariaDBMemory:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.connection = mariadb.connect(\n",
    "                host='host.docker.internal',  # Cambiado para que coincida con el contenedor\n",
    "                port=49154,  # Puerto especificado en la cadena de conexión\n",
    "                user='root',\n",
    "                password='mariadbpw',\n",
    "                database='ollama_memory'  # Asegúrate de que esta base de datos exista\n",
    "            )\n",
    "            self.connection.autocommit = True\n",
    "            print(f\"SELFCONECTION: {self.connection}\")\n",
    "            logging.info(\"Conexión a MariaDB exitosa\")\n",
    "            self.create_table()  # Crear la tabla si no existe\n",
    "        except mariadb.Error as err:\n",
    "            logging.error(f\"Error al conectar a MariaDB: {err}\")\n",
    "            self.connection = None\n",
    "\n",
    "    def create_table(self):\n",
    "        if self.connection is None:\n",
    "            logging.error(\"No se puede crear la tabla: la conexión a MariaDB no fue establecida.\")\n",
    "            return\n",
    "        cursor = self.connection.cursor()\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS memory (\n",
    "                    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                    prompt TEXT NOT NULL,\n",
    "                    response LONGTEXT NOT NULL,  # Cambiado a LONGTEXT para respuestas largas\n",
    "                    score INT DEFAULT 0\n",
    "                );\n",
    "            \"\"\")\n",
    "            logging.info(\"Tabla 'memory' asegurada.\")\n",
    "        except mariadb.Error as err:\n",
    "            logging.error(f\"Error al crear la tabla: {err}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "    def save_memory(self, prompt: str, response: dict, score: int):\n",
    "        # Verificar que alguna de las respuestas no esté vacía\n",
    "        valid_response = any(response.get(key) for key in ['ollama', 'wikipedia', 'duckduckgo'])\n",
    "\n",
    "        if not valid_response:  # Si todas las respuestas son vacías o None\n",
    "            logging.warning(\"No se guarda la respuesta vacía en la base de datos.\")\n",
    "            return\n",
    "\n",
    "        if self.connection is None:\n",
    "            logging.error(\"No se puede guardar en memoria: la conexión a MariaDB no fue establecida.\")\n",
    "            return\n",
    "        cursor = self.connection.cursor()\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO memory (prompt, response, score)\n",
    "                VALUES (%s, %s, %s);\n",
    "            \"\"\", (prompt, str(response), score))  # Convertir el diccionario en cadena para almacenar\n",
    "            logging.info(f\"Memoria guardada: {prompt} con puntaje {score}\")\n",
    "        except mariadb.Error as err:\n",
    "            logging.error(f\"Error al guardar en memoria: {err}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "    def retrieve_memory(self, prompt: str):\n",
    "        if self.connection is None:\n",
    "            logging.error(\"No se puede recuperar de memoria: la conexión a MariaDB no fue establecida.\")\n",
    "            return None\n",
    "        cursor = self.connection.cursor()\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT response, score FROM memory\n",
    "                WHERE prompt = %s;\n",
    "            \"\"\", (prompt,))\n",
    "            result = cursor.fetchone()\n",
    "            return result if result else None\n",
    "        except mariadb.Error as err:\n",
    "            logging.error(f\"Error al recuperar de memoria: {err}\")\n",
    "            return None\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "# Clase para obtener información de Wikipedia utilizando requests\n",
    "class WikipediaTool:\n",
    "    def __init__(self, language='es'):\n",
    "        self.api_url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
    "\n",
    "    def get_summary(self, query: str):\n",
    "        \"\"\"Devuelve el resumen del artículo de Wikipedia utilizando requests.\"\"\"\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"extracts\",\n",
    "            \"exintro\": True,\n",
    "            \"titles\": query,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        try:\n",
    "            logging.info(f\"Haciendo solicitud a Wikipedia para: {query}\")\n",
    "            response = requests.get(self.api_url, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                pages = data[\"query\"][\"pages\"]\n",
    "                for page_id, page_data in pages.items():\n",
    "                    logging.info(f\"Título encontrado: {page_data['title']}\")\n",
    "                    return page_data.get('extract', \"No se encontró extracto disponible.\")\n",
    "            else:\n",
    "                logging.error(f\"Error al conectarse a Wikipedia: {response.status_code}\")\n",
    "                return None\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"Error en la solicitud a Wikipedia: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_full_article(self, query: str):\n",
    "        \"\"\"Devuelve el contenido completo del artículo de Wikipedia utilizando requests.\"\"\"\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"extracts\",\n",
    "            \"titles\": query,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        try:\n",
    "            logging.info(f\"Haciendo solicitud a Wikipedia para: {query}\")\n",
    "            response = requests.get(self.api_url, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                pages = data[\"query\"][\"pages\"]\n",
    "                for page_id, page_data in pages.items():\n",
    "                    logging.info(f\"Título encontrado: {page_data['title']}\")\n",
    "                    return page_data.get('extract', \"No se encontró contenido disponible.\")\n",
    "            else:\n",
    "                logging.error(f\"Error al conectarse a Wikipedia: {response.status_code}\")\n",
    "                return None\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"Error en la solicitud a Wikipedia: {e}\")\n",
    "            return None\n",
    "\n",
    "# Clase para obtener información de DuckDuckGo\n",
    "class DuckDuckGoTool:\n",
    "    def __init__(self):\n",
    "        self.api_url = \"https://api.duckduckgo.com/\"\n",
    "\n",
    "    def get_answer(self, query: str):\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'format': 'json',\n",
    "            \"kl\": \"es-es\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(self.api_url, params=params)\n",
    "            response.raise_for_status()  # Lanzar excepción si hay error\n",
    "            data = response.json()\n",
    "            if 'AbstractText' in data and data['AbstractText']:\n",
    "                return data['AbstractText']\n",
    "            else:\n",
    "                return None  # Devuelve None si no encuentra nada\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(f\"Error en DuckDuckGo: {e}\")\n",
    "            return None\n",
    "\n",
    "# Extender el modelo Ollama para que use la memoria en MariaDB\n",
    "class OllamaWithMemory:\n",
    "    def __init__(self, model: OllamaLLM, memory: MariaDBMemory):\n",
    "        self.model = model\n",
    "        self.memory = memory\n",
    "\n",
    "    def generate_with_memory(self, prompt: str):\n",
    "        # Intentar recuperar de la memoria\n",
    "        memory_response = self.memory.retrieve_memory(prompt)\n",
    "        if memory_response:\n",
    "            logging.info(\"Respuesta encontrada en memoria.\")\n",
    "            return memory_response\n",
    "\n",
    "        # Si no está en memoria, generar nueva respuesta\n",
    "        logging.info(\"Generando nueva respuesta...\")\n",
    "        response = self.model.generate(prompt)\n",
    "        if response:  # Solo guarda si hay una respuesta válida\n",
    "            return response, 1  # Retornar respuesta con puntaje 1 si solo Ollama respondió\n",
    "        return None, 0\n",
    "\n",
    "# Integración de Ollama, Wikipedia y DuckDuckGo con memoria y sistema de puntaje\n",
    "class OllamaWithMemoryAndTools(OllamaWithMemory):\n",
    "    def __init__(self, model: OllamaLLM, memory: MariaDBMemory, tools: dict):\n",
    "        super().__init__(model=model, memory=memory)\n",
    "        self.tools = tools\n",
    "        self.stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "    def clean_question(self, question: str):\n",
    "        \"\"\"Limpia la pregunta eliminando stopwords y caracteres innecesarios.\"\"\"\n",
    "        # Convertir a minúsculas y eliminar caracteres especiales\n",
    "        question_cleaned = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑ\\s]', '', question.lower())\n",
    "        \n",
    "        # Dividir en palabras y eliminar stopwords\n",
    "        words = question_cleaned.split()\n",
    "        important_words = [word for word in words if word not in self.stop_words]\n",
    "        \n",
    "        # Unir las palabras importantes de nuevo en una cadena\n",
    "        return ' '.join(important_words)\n",
    "\n",
    "    def ask(self, question: str, full_article=True):\n",
    "        # Generar respuesta utilizando memoria y herramientas\n",
    "        ollama_response, score = self.generate_with_memory(question)\n",
    "        wikipedia_response = None\n",
    "        duckduckgo_response = None\n",
    "\n",
    "        # Limpiar la pregunta para extraer el tema\n",
    "        cleaned_topic = self.clean_question(question)\n",
    "        \n",
    "        # Intentar recuperar de memoria primero\n",
    "        memory_data = self.memory.retrieve_memory(cleaned_topic)\n",
    "        if memory_data:\n",
    "            logging.info(f\"Datos encontrados en memoria para: {cleaned_topic}\")\n",
    "            responses, stored_score = json.loads(memory_data[0]), memory_data[1]\n",
    "            \n",
    "            # Verificamos si falta alguna respuesta (Wikipedia o DuckDuckGo)\n",
    "            if not responses.get('wikipedia'):\n",
    "                logging.info(\"No se encontró respuesta de Wikipedia, intentando recuperarla...\")\n",
    "                if full_article:\n",
    "                    wikipedia_response = self.tools['wikipedia'].get_full_article(cleaned_topic)\n",
    "                else:\n",
    "                    wikipedia_response = self.tools['wikipedia'].get_summary(cleaned_topic)\n",
    "                if wikipedia_response:\n",
    "                    responses['wikipedia'] = wikipedia_response\n",
    "                    score += 1\n",
    "            \n",
    "            if not responses.get('duckduckgo'):\n",
    "                logging.info(\"No se encontró respuesta de DuckDuckGo, intentando recuperarla...\")\n",
    "                duckduckgo_response = self.tools['duckduckgo'].get_answer(cleaned_topic)\n",
    "                if duckduckgo_response:\n",
    "                    responses['duckduckgo'] = duckduckgo_response\n",
    "                    score += 1\n",
    "\n",
    "            # Si alguna respuesta faltaba y la recuperamos, actualizamos en memoria\n",
    "            if wikipedia_response or duckduckgo_response:\n",
    "                self.memory.save_memory(question, responses, score)\n",
    "\n",
    "            return responses, score\n",
    "\n",
    "        # Si no hay memoria, hacemos las consultas normalmente\n",
    "        if cleaned_topic:\n",
    "            logging.info(f\"Buscando en Wikipedia: {cleaned_topic}\")\n",
    "            if full_article:\n",
    "                wikipedia_response = self.tools['wikipedia'].get_full_article(cleaned_topic)  # Obtener artículo completo\n",
    "            else:\n",
    "                wikipedia_response = self.tools['wikipedia'].get_summary(cleaned_topic)  # Obtener solo el resumen\n",
    "            \n",
    "            if wikipedia_response:\n",
    "                logging.info(f\"Respuesta de Wikipedia recibida para {cleaned_topic}\")\n",
    "                logging.info(f\"RESPUESTA WIKIPEDIA: {wikipedia_response}\")\n",
    "                score += 1\n",
    "            else:\n",
    "                logging.error(f\"No se encontró información en Wikipedia para {cleaned_topic}\")\n",
    "        \n",
    "        duckduckgo_response = self.tools['duckduckgo'].get_answer(cleaned_topic if cleaned_topic else question)\n",
    "        if duckduckgo_response:\n",
    "            logging.info(f\"Respuesta de DuckDuckGo recibida para {cleaned_topic or question}\")\n",
    "            score += 1\n",
    "        else:\n",
    "            logging.error(f\"No se encontró información en DuckDuckGo para {cleaned_topic or question}\")\n",
    "\n",
    "        # Guardar todas las respuestas separadas\n",
    "        responses = {\n",
    "            \"ollama\": ollama_response,\n",
    "            \"wikipedia\": wikipedia_response,\n",
    "            \"duckduckgo\": duckduckgo_response\n",
    "        }\n",
    "\n",
    "        if ollama_response:\n",
    "            # Guardar solo si Ollama responde correctamente\n",
    "            self.memory.save_memory(question, responses, score)\n",
    "\n",
    "        return responses, score  # Retorna todas las respuestas por separado con puntaje\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "ollama_llm = OllamaLLM()\n",
    "mariadb_memory = MariaDBMemory()\n",
    "\n",
    "# Herramientas\n",
    "wikipedia_tool = WikipediaTool(language=\"es\")\n",
    "duckduckgo_tool = DuckDuckGoTool()\n",
    "\n",
    "tools = {\n",
    "    \"wikipedia\": wikipedia_tool,\n",
    "    \"duckduckgo\": duckduckgo_tool\n",
    "}\n",
    "\n",
    "# Crear la instancia de Ollama con memoria y herramientas\n",
    "ollama_with_memory_and_tools = OllamaWithMemoryAndTools(\n",
    "    model=ollama_llm, \n",
    "    memory=mariadb_memory, \n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Hacer una pregunta\n",
    "response = ollama_with_memory_and_tools.ask(\"¿Quién fue Albert Einstein?\")\n",
    "print(\"Respuesta:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Selecciona el modelo que deseas usar\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"  # O \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Mover el modelo a GPU si está disponible\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "# Función para generar texto\n",
    "def generate_text(prompt, max_length=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Usar la función\n",
    "prompt = \"¿Cuál es el futuro de la inteligencia artificial?\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
